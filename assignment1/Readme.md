# Assignment 1

### Linear Regression | Gradient Descent

Implementing Gradient Descent algorithm to compute optimal parameters for a linear hypothesis. At each training step, the gradient of the MSE loss is computed, and used to take one step, with the step size (or learning rate) set as 0.1. The change of loss with change in parameters, along with change in the hypothesis, as the model is trained, can be seen in the gif below. 

<p align="center">
    <img src="./assets/gradient_descent.gif"/> 
</p>

Further detailed analysis of the algorithm for different step sizes (or learning rates) can be found in the [report](./COL774_ass1_report.pdf), while the code implementation can be found in [Q1](./Q1).

### Stochastic Gradient Descent

### Newton's Method | Logistic Regression

### Gaussian Discriminant Analysis
